# ğŸ¯ RESUMEN DEL PROYECTO

## Â¿QuÃ© hace este sistema?

Este sistema es una **soluciÃ³n Docker 100% local** que:

1. **Transcribe archivos de audio** de larga duraciÃ³n usando Whisper de OpenAI
2. **Formatea automÃ¡ticamente** las transcripciones usando **Ollama (100% local y gratuito)**
3. **Genera anÃ¡lisis avanzado** (resÃºmenes, puntos clave, temas principales)
4. **Procesa mÃºltiples archivos** en lote
5. **Funciona completamente offline** - No requiere internet despuÃ©s de la instalaciÃ³n inicial

## ğŸ“¦ Estructura del Proyecto Creado

```
d:\PRUEBA CREAR TRANSCRIPCION\
â”‚
â”œâ”€â”€ ğŸ“„ Dockerfile                    # ConfiguraciÃ³n de la imagen Docker
â”œâ”€â”€ ğŸ“„ docker-compose.yml            # OrquestaciÃ³n de servicios (Ollama + Transcriptor)
â”œâ”€â”€ ğŸ“„ requirements.txt              # Dependencias Python
â”œâ”€â”€ ğŸ“„ .env.example                  # Plantilla de configuraciÃ³n
â”œâ”€â”€ ğŸ“„ .env                          # Tu configuraciÃ³n (creado automÃ¡ticamente)
â”œâ”€â”€ ğŸ“„ .gitignore                    # Archivos a ignorar en Git
â”œâ”€â”€ ğŸ“„ .dockerignore                 # Archivos a ignorar en Docker
â”‚
â”œâ”€â”€ ğŸ“ src/                          # CÃ³digo fuente
â”‚   â”œâ”€â”€ main.py                      # Orquestador principal
â”‚   â”œâ”€â”€ transcribe.py                # Motor de transcripciÃ³n (Whisper)
â”‚   â”œâ”€â”€ format_ollama.py             # Motor de formateo (Ollama - LOCAL)
â”‚   â””â”€â”€ format_gemini.py             # Motor de formateo alternativo (Gemini - requiere API)
â”‚
â”œâ”€â”€ ğŸ“ input/                        # COLOCA TUS ARCHIVOS DE AUDIO AQUÃ
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ ğŸ“ output/                       # AQUÃ APARECEN LAS TRANSCRIPCIONES
â”‚   â””â”€â”€ README.md                    # 6 archivos por audio (transcripciÃ³n + anÃ¡lisis)
â”‚
â”œâ”€â”€ ğŸ“ logs/                         # Logs de ejecuciÃ³n
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ ğŸ“œ run.ps1                       # Script principal de ejecuciÃ³n
â”œâ”€â”€ ğŸ“œ clean.ps1                     # Script de limpieza
â”œâ”€â”€ ğŸ“œ verify.ps1                    # Script de verificaciÃ³n
â”‚
â”œâ”€â”€ ğŸ“– README.md                     # DocumentaciÃ³n completa
â”œâ”€â”€ ğŸ“– QUICKSTART.md                 # GuÃ­a de inicio rÃ¡pido
â””â”€â”€ ğŸ“– PROYECTO.md                   # Este archivo
```

## ğŸ”„ EvoluciÃ³n del Proyecto

| Aspecto | VersiÃ³n Inicial (Gemini) | VersiÃ³n Actual (Ollama) |
|---------|--------------------------|-------------------------|
| **Formateo** | Google Gemini (requiere API key) | Ollama local (100% gratuito) |
| **Internet** | Necesario para formateo | Solo instalaciÃ³n inicial |
| **Costo** | $$ por llamadas API | Completamente gratis |
| **Privacidad** | Datos enviados a Google | Todo local en tu PC |
| **AnÃ¡lisis** | Solo formateo bÃ¡sico | ResÃºmenes + Puntos clave + Temas |
| **ConfiguraciÃ³n** | Manual compleja | AutomÃ¡tica (run.ps1) |
| **Modelos** | Limitado a Gemini | MÃºltiples modelos Ollama |
| **GPU** | Soporte bÃ¡sico | Optimizado para GPUs 6GB+ |

## ğŸš€ Pasos para Empezar

### 1. Instalar Docker (solo primera vez)

**Docker no estÃ¡ instalado en tu sistema.** DescÃ¡rgalo aquÃ­:

ğŸ‘‰ **Windows**: https://www.docker.com/products/docker-desktop

**Pasos de instalaciÃ³n:**
1. Descarga Docker Desktop para Windows
2. Ejecuta el instalador
3. Reinicia tu PC si es necesario
4. Abre Docker Desktop y espera que inicie completamente
5. Verifica la instalaciÃ³n ejecutando:
   ```powershell
   docker --version
   docker-compose --version
   ```

### 2. Configurar el Proyecto

```powershell
# La configuraciÃ³n estÃ¡ lista para usar con valores Ã³ptimos

# Opcional: Editar configuraciÃ³n avanzada
notepad .env

# NO necesitas API Keys - Todo es local con Ollama
# El script run.ps1 descargarÃ¡ automÃ¡ticamente el modelo llama3.2:3b (~2GB)
```

### 3. Agregar Archivos de Audio

```powershell
# Copiar tus archivos de audio a la carpeta input
Copy-Item "C:\ruta\a\tu\audio.mp3" input\

# O mÃºltiples archivos
Copy-Item "C:\ruta\a\tus\audios\*.m4a" input\
```

### 4. Ejecutar

```powershell
# OpciÃ³n 1: Usar el script automÃ¡tico (recomendado)
.\run.ps1

# OpciÃ³n 2: Manualmente
docker-compose build
docker-compose up
```

### 5. Ver Resultados

Los archivos procesados aparecerÃ¡n en `output/` (6 archivos por audio):

**Transcripciones bÃ¡sicas (Whisper):**
- `*_transcripcion.txt` - Texto limpio sin timestamps
- `*_transcripcion_detallada.txt` - Con timestamps [MM:SS.000]

**AnÃ¡lisis avanzado (Ollama):**
- `*_transcripcion_formateada.txt` - Texto estructurado con pÃ¡rrafos
- `*_resumen.txt` - Resumen ejecutivo de 3-5 pÃ¡rrafos
- `*_puntos_clave.txt` - Lista de conceptos importantes
- `*_temas.txt` - Temas principales identificados

## ğŸ›ï¸ ConfiguraciÃ³n Recomendada

En el archivo `.env`:

```env
# ConfiguraciÃ³n base (ya incluida)
MODE=full                    # Transcribir + Formatear + Analizar
FORMATTER=ollama             # Motor de formateo (100% local)
AUDIO_LANGUAGE=es            # Idioma del audio

# Modelo Whisper segÃºn tu GPU
WHISPER_MODEL=small          # Para GPUs 6GB (RTX 2060, 1060 6GB)
# WHISPER_MODEL=medium       # Para GPUs 8GB+ (RTX 3060, 2070)
# WHISPER_MODEL=large        # Para GPUs 12GB+ (RTX 3080, 4070)

# LÃ­mite de memoria GPU
GPU_MEMORY_LIMIT=2048        # 2GB para modelo small
# GPU_MEMORY_LIMIT=4096      # 4GB para modelo medium

# Modelo Ollama (se descarga automÃ¡ticamente)
OLLAMA_MODEL=llama3.2:3b     # Ligero y rÃ¡pido (~2GB)

# AnÃ¡lisis avanzado (activado por defecto)
ENABLE_SUMMARY=true          # Resumen ejecutivo
ENABLE_KEY_POINTS=true       # Puntos clave
ENABLE_TOPICS=true           # Temas principales
```

## ğŸ’¡ Ventajas de esta SoluciÃ³n

âœ… **100% Local** - No envÃ­a tus datos a ningÃºn servidor
âœ… **100% Gratuito** - No requiere API keys ni suscripciones
âœ… **Sin Internet** - Funciona offline despuÃ©s de instalaciÃ³n inicial
âœ… **Procesamiento en lote** - MÃºltiples archivos automÃ¡ticamente
âœ… **AnÃ¡lisis avanzado** - ResÃºmenes, puntos clave, temas automÃ¡ticos
âœ… **ConfiguraciÃ³n automÃ¡tica** - El script run.ps1 descarga todo lo necesario
âœ… **Optimizado para GPU** - Configuraciones preestablecidas para GPUs comunes
âœ… **Repetible** - Mismos resultados siempre
âœ… **Portable** - Comparte el proyecto fÃ¡cilmente
âœ… **Logs completos** - Debugging mÃ¡s fÃ¡cil

## ğŸ“Š Recursos Necesarios

### Modelos Whisper (TranscripciÃ³n)

| Modelo | VRAM GPU | Tiempo (1h audio) | Calidad | GPU Recomendada |
|--------|----------|-------------------|---------|-----------------|
| tiny   | ~1 GB    | ~3 min            | BÃ¡sica  | Cualquiera      |
| base   | ~1 GB    | ~5 min            | Aceptable | Cualquiera    |
| **small** | **~2 GB** | **~8 min**     | **Buena** | **RTX 2060 6GB** âœ… |
| medium | ~5 GB    | ~15 min           | Excelente | RTX 3060 12GB  |
| large  | ~10 GB   | ~30 min           | MÃ¡xima  | RTX 3080 12GB   |

### Modelos Ollama (Formateo y AnÃ¡lisis)

| Modelo | TamaÃ±o | VRAM | Velocidad | Calidad |
|--------|--------|------|-----------|---------|
| **llama3.2:3b** | **2 GB** | **~600 MB** | **RÃ¡pida** | **Excelente** âœ… |
| llama3.2:1b | 1 GB | ~400 MB | Muy rÃ¡pida | Buena |
| llama3:8b | 4.5 GB | ~2 GB | Media | Superior |
| mistral | 4 GB | ~1.5 GB | Media | Excelente |

### ConfiguraciÃ³n Ã“ptima para GPUs 6GB (RTX 2060)

```env
WHISPER_MODEL=small           # 2GB VRAM
GPU_MEMORY_LIMIT=2048         # LÃ­mite seguro
OLLAMA_MODEL=llama3.2:3b      # 600MB VRAM
```

**Total usado:** ~0.9GB Whisper + ~0.6GB Ollama = **~1.5GB** (25% de 6GB) âœ…

## â“ FAQ

**P: Â¿Necesito internet?**
R: Solo para la instalaciÃ³n inicial (descargar Docker, modelos Whisper y Ollama). DespuÃ©s funciona 100% offline.

**P: Â¿Necesito una API key de Google/OpenAI?**
R: NO. Todo funciona localmente con Ollama. Es 100% gratuito.

**P: Â¿Se envÃ­an mis audios a algÃºn servidor?**
R: NO. Todo el procesamiento es local en tu PC. Privacidad total.

**P: Â¿Funciona con GPU?**
R: SÃ­, automÃ¡ticamente detecta y usa GPU NVIDIA si estÃ¡ disponible. Configuraciones preestablecidas para GPUs 6GB, 8GB y 12GB.

**P: Â¿El script run.ps1 descarga todo automÃ¡ticamente?**
R: SÃ­, verifica e instala el modelo llama3.2:3b si no existe (~2GB). Primera ejecuciÃ³n puede tardar 5-10 minutos.

**P: Â¿Puedo transcribir sin anÃ¡lisis/formateo?**
R: SÃ­, cambia `MODE=transcribe-only` en `.env`.

**P: Â¿Puedo desactivar solo algunos anÃ¡lisis?**
R: SÃ­, en `.env` configura:
```env
ENABLE_SUMMARY=false      # Desactivar resumen
ENABLE_KEY_POINTS=true    # Mantener puntos clave
ENABLE_TOPICS=true        # Mantener temas
```

**P: Â¿CuÃ¡nto tarda?**
R: Con `small` + `llama3.2:3b`, aproximadamente **10-15 minutos por hora de audio** (transcripciÃ³n + anÃ¡lisis completo).

**P: Â¿QuÃ© formatos de audio acepta?**
R: MP3, WAV, M4A, FLAC, AAC, OGG, WMA, OPUS, MP4 (audio) y mÃ¡s.

**P: Â¿Puedo usar modelos mÃ¡s potentes?**
R: SÃ­, edita en `.env`:
- `WHISPER_MODEL=medium` o `large` (requiere mÃ¡s VRAM)
- `OLLAMA_MODEL=llama3:8b` o `mistral` (mejor calidad, mÃ¡s lento)

## ğŸ”§ Comandos Ãštiles

```powershell
# Verificar que todo estÃ¡ listo
.\verify.ps1

# Ejecutar el sistema
.\run.ps1

# Limpiar todo
.\clean.ps1

# Ver logs en tiempo real
docker-compose logs -f

# Detener el contenedor
docker-compose down

# Reconstruir la imagen
docker-compose build --no-cache
```

## ğŸ“ Soporte

Si tienes problemas:

1. Ejecuta `.\verify.ps1` para diagnosticar
2. Revisa los logs en `logs/`
3. Consulta el `README.md` completo
4. Revisa que Docker estÃ© corriendo

## ğŸ‰ Â¡Listo para usar!

Una vez que instales Docker:

```powershell
.\verify.ps1      # Verifica que todo estÃ© bien
.\run.ps1         # Ejecuta el sistema
```

## ğŸ”§ Problemas Resueltos en Versiones Recientes

### âœ… VersiÃ³n 1.3 (Noviembre 2025)

**Problema 1:** Modelo Ollama no se descargaba automÃ¡ticamente
- âœ… **SoluciÃ³n:** `run.ps1` ahora verifica y descarga `llama3.2:3b` automÃ¡ticamente

**Problema 2:** Docker mostraba Ollama como "unhealthy" aunque funcionaba
- âœ… **SoluciÃ³n:** Eliminado healthcheck problemÃ¡tico de `docker-compose.yml`

**Problema 3:** Variables de anÃ¡lisis (ENABLE_*) no se pasaban al contenedor
- âœ… **SoluciÃ³n:** Agregadas al `.env` y `docker-compose.yml`

**Problema 4:** GPU Out of Memory con RTX 2060 6GB
- âœ… **SoluciÃ³n:** Configuraciones optimizadas para GPUs comunes (small + 2GB lÃ­mite)

### ğŸ“¦ Commits Importantes

- `383818e` - Variables ENABLE_* para control de anÃ¡lisis
- `de2f1c6` - EliminaciÃ³n de healthcheck problemÃ¡tico
- `7bb7f72` - Descarga automÃ¡tica del modelo Ollama
- `ba4b189` - Sistema de anÃ¡lisis avanzado con Ollama

---

**SoluciÃ³n profesional 100% local y gratuita**  
De transcripciÃ³n bÃ¡sica a anÃ¡lisis completo con IA local.
