# üéØ RESUMEN DEL PROYECTO

## ¬øQu√© hace este sistema?

Este sistema es una **soluci√≥n Docker 100% local** que:

1. **Transcribe archivos de audio** de larga duraci√≥n usando Whisper de OpenAI
2. **Formatea autom√°ticamente** las transcripciones usando **Ollama (100% local y gratuito)**
3. **Genera an√°lisis avanzado** (res√∫menes, puntos clave, temas principales)
4. **Procesa m√∫ltiples archivos** en lote
5. **Funciona completamente offline** - No requiere internet despu√©s de la instalaci√≥n inicial

## üì¶ Estructura del Proyecto Creado

```
d:\PRUEBA CREAR TRANSCRIPCION\
‚îÇ
‚îú‚îÄ‚îÄ üìÑ Dockerfile                    # Configuraci√≥n de la imagen Docker
‚îú‚îÄ‚îÄ üìÑ docker-compose.yml            # Orquestaci√≥n de servicios (Ollama + Transcriptor)
‚îú‚îÄ‚îÄ üìÑ requirements.txt              # Dependencias Python
‚îú‚îÄ‚îÄ üìÑ .env.example                  # Plantilla de configuraci√≥n
‚îú‚îÄ‚îÄ üìÑ .env                          # Tu configuraci√≥n (creado autom√°ticamente)
‚îú‚îÄ‚îÄ üìÑ .gitignore                    # Archivos a ignorar en Git
‚îú‚îÄ‚îÄ üìÑ .dockerignore                 # Archivos a ignorar en Docker
‚îÇ
‚îú‚îÄ‚îÄ üìÅ src/                          # C√≥digo fuente
‚îÇ   ‚îú‚îÄ‚îÄ main.py                      # Orquestador principal
‚îÇ   ‚îú‚îÄ‚îÄ transcribe.py                # Motor de transcripci√≥n (Whisper)
‚îÇ   ‚îú‚îÄ‚îÄ format_ollama.py             # Motor de formateo (Ollama - LOCAL)
‚îÇ   ‚îî‚îÄ‚îÄ format_gemini.py             # Motor de formateo alternativo (Gemini - requiere API)
‚îÇ
‚îú‚îÄ‚îÄ üìÅ input/                        # COLOCA TUS ARCHIVOS DE AUDIO AQU√ç
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îÇ
‚îú‚îÄ‚îÄ üìÅ output/                       # AQU√ç APARECEN LAS TRANSCRIPCIONES
‚îÇ   ‚îî‚îÄ‚îÄ README.md                    # 6 archivos por audio (transcripci√≥n + an√°lisis)
‚îÇ
‚îú‚îÄ‚îÄ üìÅ logs/                         # Logs de ejecuci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îÇ
‚îú‚îÄ‚îÄ üìú run.ps1                       # Men√∫ interactivo principal
‚îÇ
‚îú‚îÄ‚îÄ üìñ README.md                     # Documentaci√≥n completa
‚îú‚îÄ‚îÄ üìñ QUICKSTART.md                 # Gu√≠a de inicio r√°pido
‚îî‚îÄ‚îÄ üìñ PROYECTO.md                   # Este archivo
```

## üîÑ Evoluci√≥n del Proyecto

| Aspecto | Versi√≥n Inicial (Gemini) | Versi√≥n Actual (Ollama) |
|---------|--------------------------|-------------------------|
| **Formateo** | Google Gemini (requiere API key) | Ollama local (100% gratuito) |
| **Internet** | Necesario para formateo | Solo instalaci√≥n inicial |
| **Costo** | $$ por llamadas API | Completamente gratis |
| **Privacidad** | Datos enviados a Google | Todo local en tu PC |
| **An√°lisis** | Solo formateo b√°sico | Res√∫menes + Puntos clave + Temas |
| **Configuraci√≥n** | Manual compleja | Autom√°tica (run.ps1) |
| **Modelos** | Limitado a Gemini | M√∫ltiples modelos Ollama |
| **GPU** | Soporte b√°sico | Optimizado para GPUs 6GB+ |

## üöÄ Pasos para Empezar

> **¬øNecesito una GPU o tarjeta gr√°fica potente?**
> 
> **NO.** El sistema funciona en cualquier PC moderna:
> - ‚úÖ **Con GPU NVIDIA:** Transcripci√≥n m√°s r√°pida (~15 min/hora)
> - ‚úÖ **Sin GPU:** Usa tu procesador normal (~30 min/hora)
> - ‚úÖ **No sabes qu√© tienes:** Funciona igual, detecci√≥n autom√°tica
> - ‚úÖ **Calidad id√©ntica:** Con o sin GPU, los resultados son los mismos
> 
> El sistema detecta tu hardware autom√°ticamente y se adapta.

### 1. Instalar Docker (solo primera vez)

**Docker no est√° instalado en tu sistema.** Desc√°rgalo aqu√≠:

üëâ **Windows**: https://www.docker.com/products/docker-desktop

**Pasos de instalaci√≥n:**
1. Descarga Docker Desktop para Windows
2. Ejecuta el instalador
3. Reinicia tu PC si es necesario
4. Abre Docker Desktop y espera que inicie completamente
5. Verifica la instalaci√≥n ejecutando:
   ```powershell
   docker --version
   docker-compose --version
   ```

### 2. Agregar Archivos de Audio

```powershell
# Opci√≥n 1: Copiar manualmente
Copy-Item "C:\ruta\a\tu\audio.mp3" input\

# Opci√≥n 2: Arrastra y suelta
# Abre la carpeta "input" y arrastra tus archivos .mp3, .m4a, .wav, etc.
```

### 3. Ejecutar el Men√∫ Interactivo

```powershell
.\run.ps1
```

**El men√∫ te guiar√° paso a paso:**

```
========================================
  üéôÔ∏è  TRANSCRIPTOR DE AUDIO
  Whisper + Ollama (100% Local)
========================================

MEN√ö PRINCIPAL

1. üöÄ Transcribir y Formatear (Proceso Completo)
2. üé§ Solo Transcribir (Whisper)
3. ‚ú® Solo Formatear (Ollama)
4. üîß Configuraci√≥n y Mantenimiento
5. üìä Ver Estado del Sistema
6. üóëÔ∏è  Limpiar Archivos de Salida
7. ‚ùå Salir
```

**Primera vez:**
- Selecciona opci√≥n **4** ‚Üí **1** (Primera Instalaci√≥n)
- El sistema descargar√° todo autom√°ticamente (~15-30 min)

**Usos posteriores:**
- Selecciona opci√≥n **1** (Proceso Completo)
- Todo funciona autom√°ticamente

### 5. Ver Resultados

Los archivos procesados aparecer√°n en `output/` (6 archivos por audio):

**Transcripciones b√°sicas (Whisper):**
- `*_transcripcion.txt` - Texto limpio sin timestamps
- `*_transcripcion_detallada.txt` - Con timestamps [MM:SS.000]

**An√°lisis avanzado (Ollama):**
- `*_transcripcion_formateada.txt` - Texto estructurado con p√°rrafos
- `*_resumen.txt` - Resumen ejecutivo de 3-5 p√°rrafos
- `*_puntos_clave.txt` - Lista de conceptos importantes
- `*_temas.txt` - Temas principales identificados

## üéõÔ∏è Configuraci√≥n Recomendada

En el archivo `.env`:

```env
# Configuraci√≥n base (ya incluida)
MODE=full                    # Transcribir + Formatear + Analizar
FORMATTER=ollama             # Motor de formateo (100% local)
AUDIO_LANGUAGE=es            # Idioma del audio
AUDIO_DIALECT=cl             # Espa√±ol chileno (detecta modismos)

# Modelo Whisper seg√∫n tu GPU
WHISPER_MODEL=small          # Para GPUs 6GB (RTX 2060, 1060 6GB)
# WHISPER_MODEL=medium       # Para GPUs 8GB+ (RTX 3060, 2070)
# WHISPER_MODEL=large        # Para GPUs 12GB+ (RTX 3080, 4070)

# L√≠mite de memoria GPU
GPU_MEMORY_LIMIT=2048        # 2GB para modelo small
# GPU_MEMORY_LIMIT=4096      # 4GB para modelo medium

# Modelo Ollama (se descarga autom√°ticamente)
OLLAMA_MODEL=llama3.2:3b     # Ligero y r√°pido (~2GB)

# An√°lisis avanzado (activado por defecto)
ENABLE_SUMMARY=true          # Resumen ejecutivo
ENABLE_KEY_POINTS=true       # Puntos clave
ENABLE_TOPICS=true           # Temas principales
```

## üí° Ventajas de esta Soluci√≥n

‚úÖ **100% Local** - No env√≠a tus datos a ning√∫n servidor
‚úÖ **100% Gratuito** - No requiere API keys ni suscripciones
‚úÖ **Sin Internet** - Funciona offline despu√©s de instalaci√≥n inicial
‚úÖ **Procesamiento en lote** - M√∫ltiples archivos autom√°ticamente
‚úÖ **An√°lisis avanzado** - Res√∫menes, puntos clave, temas autom√°ticos
‚úÖ **Configuraci√≥n autom√°tica** - El script run.ps1 descarga todo lo necesario
‚úÖ **Optimizado para GPU** - Configuraciones preestablecidas para GPUs comunes
‚úÖ **Repetible** - Mismos resultados siempre
‚úÖ **Portable** - Comparte el proyecto f√°cilmente
‚úÖ **Logs completos** - Debugging m√°s f√°cil

## üìä Recursos Necesarios

### Modelos Whisper (Transcripci√≥n)

| Modelo | VRAM GPU | Tiempo (1h audio) | Calidad | GPU Recomendada |
|--------|----------|-------------------|---------|-----------------|
| tiny   | ~1 GB    | ~3 min            | B√°sica  | Cualquiera      |
| base   | ~1 GB    | ~5 min            | Aceptable | Cualquiera    |
| **small** | **~2 GB** | **~8 min**     | **Buena** | **RTX 2060 6GB** ‚úÖ |
| medium | ~5 GB    | ~15 min           | Excelente | RTX 3060 12GB  |
| large  | ~10 GB   | ~30 min           | M√°xima  | RTX 3080 12GB   |

### Modelos Ollama (Formateo y An√°lisis)

| Modelo | Tama√±o | VRAM | Velocidad | Calidad |
|--------|--------|------|-----------|---------|
| **llama3.2:3b** | **2 GB** | **~600 MB** | **R√°pida** | **Excelente** ‚úÖ |
| llama3.2:1b | 1 GB | ~400 MB | Muy r√°pida | Buena |
| llama3:8b | 4.5 GB | ~2 GB | Media | Superior |
| mistral | 4 GB | ~1.5 GB | Media | Excelente |

### Configuraci√≥n √ìptima para GPUs 6GB (RTX 2060)

```env
WHISPER_MODEL=small           # 2GB VRAM
GPU_MEMORY_LIMIT=2048         # L√≠mite seguro
OLLAMA_MODEL=llama3.2:3b      # 600MB VRAM
```

**Total usado:** ~0.9GB Whisper + ~0.6GB Ollama = **~1.5GB** (25% de 6GB) ‚úÖ

## ‚ùì FAQ

**P: ¬øNecesito internet?**
R: Solo para la instalaci√≥n inicial (descargar Docker, modelos Whisper y Ollama). Despu√©s funciona 100% offline.

**P: ¬øNecesito una API key de Google/OpenAI?**
R: NO. Todo funciona localmente con Ollama. Es 100% gratuito.

**P: ¬øSe env√≠an mis audios a alg√∫n servidor?**
R: NO. Todo el procesamiento es local en tu PC. Privacidad total.

**P: ¬øFunciona con GPU?**
R: S√≠, autom√°ticamente detecta y usa GPU NVIDIA si est√° disponible. Configuraciones preestablecidas para GPUs 6GB, 8GB y 12GB.

**P: ¬øEl script run.ps1 descarga todo autom√°ticamente?**
R: S√≠, verifica e instala el modelo llama3.2:3b si no existe (~2GB). Primera ejecuci√≥n puede tardar 5-10 minutos.

**P: ¬øPuedo transcribir sin an√°lisis/formateo?**
R: S√≠, cambia `MODE=transcribe-only` en `.env`.

**P: ¬øPuedo desactivar solo algunos an√°lisis?**
R: S√≠, en `.env` configura:
```env
ENABLE_SUMMARY=false      # Desactivar resumen
ENABLE_KEY_POINTS=true    # Mantener puntos clave
ENABLE_TOPICS=true        # Mantener temas
```

**P: ¬øCu√°nto tarda?**
R: Con `small` + `llama3.2:3b`, aproximadamente **10-15 minutos por hora de audio** (transcripci√≥n + an√°lisis completo).

**P: ¬øQu√© formatos de audio acepta?**
R: MP3, WAV, M4A, FLAC, AAC, OGG, WMA, OPUS, MP4 (audio) y m√°s.

**P: ¬øPuedo usar modelos m√°s potentes?**
R: S√≠, edita en `.env`:
- `WHISPER_MODEL=medium` o `large` (requiere m√°s VRAM)
- `OLLAMA_MODEL=llama3:8b` o `mistral` (mejor calidad, m√°s lento)

## üîß Comandos √ötiles

```powershell
# Verificar que todo est√° listo
.\verify.ps1

# Ejecutar el sistema
.\run.ps1

# Limpiar todo
.\clean.ps1

# Ver logs en tiempo real
docker-compose logs -f

# Detener el contenedor
docker-compose down

# Reconstruir la imagen
docker-compose build --no-cache
```

## üìû Soporte

Si tienes problemas:

1. Ejecuta `.\verify.ps1` para diagnosticar
2. Revisa los logs en `logs/`
3. Consulta el `README.md` completo
4. Revisa que Docker est√© corriendo

## üéâ ¬°Listo para usar!

Una vez que instales Docker:

```powershell
.\verify.ps1      # Verifica que todo est√© bien
.\run.ps1         # Ejecuta el sistema
```

## üîß Problemas Resueltos en Versiones Recientes

### ‚úÖ Versi√≥n 1.3 (Noviembre 2025)

**Problema 1:** Modelo Ollama no se descargaba autom√°ticamente
- ‚úÖ **Soluci√≥n:** `run.ps1` ahora verifica y descarga `llama3.2:3b` autom√°ticamente

**Problema 2:** Docker mostraba Ollama como "unhealthy" aunque funcionaba
- ‚úÖ **Soluci√≥n:** Eliminado healthcheck problem√°tico de `docker-compose.yml`

**Problema 3:** Variables de an√°lisis (ENABLE_*) no se pasaban al contenedor
- ‚úÖ **Soluci√≥n:** Agregadas al `.env` y `docker-compose.yml`

**Problema 4:** GPU Out of Memory con RTX 2060 6GB
- ‚úÖ **Soluci√≥n:** Configuraciones optimizadas para GPUs comunes (small + 2GB l√≠mite)

### üì¶ Commits Importantes

- `383818e` - Variables ENABLE_* para control de an√°lisis
- `de2f1c6` - Eliminaci√≥n de healthcheck problem√°tico
- `7bb7f72` - Descarga autom√°tica del modelo Ollama
- `ba4b189` - Sistema de an√°lisis avanzado con Ollama

---

**Soluci√≥n profesional 100% local y gratuita**  
De transcripci√≥n b√°sica a an√°lisis completo con IA local.
